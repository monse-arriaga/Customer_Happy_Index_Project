# ==========================================
# Pipeline simplificado: usar embeddings existentes + UMAP opcional + SemAxis + clustering 2 clusters
# ==========================================
import os
import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from umap import UMAP
from sklearn.cluster import KMeans

# -------------------------------
# Configuraci√≥n
# -------------------------------
ARCHIVO_TWEETS = "tweets_bertopic.csv"
ARCHIVO_EMBEDDINGS = "D:/Customer_Happy_Index_Project/embeddings_multilingue.npy"
ARCHIVO_FINAL = "tweets_clusters_semaxis.csv"
DEFAULT_MODELO = "paraphrase-multilingual-MiniLM-L12-v2"

# -------------------------------
# Semillas de emociones (bigramas incluidos)
# -------------------------------
# Espa√±ol
neg_es = [
    "frustraci√≥n","tardado","enojo","ira","molestia","enfado","robo","asalto",
    "inseguro","inseguridad","miedo","caro","costoso","insatisfacci√≥n","insatisfecho",
    "lento","mal servicio","deficiente","problema","error","fallo","decepci√≥n",
    "estr√©s","incidente","atraso","demora","cancelaci√≥n","inc√≥modo","sucio",
    "ruidoso","masificado","hacinamiento","desorganizado","falto de respeto",
    "peligroso","espera larga","clima adverso","mal se√±alizado","confusi√≥n",
    "desinformaci√≥n","agotador","incivilidad","mala atenci√≥n","inexacto",
    "inconveniente","sobreventa","mal mantenimiento","inseguridad vial","desagradable","frustrante",
    "perder"
]

pos_es = [
    "satisfacci√≥n","r√°pido","alegr√≠a","confianza","seguro","barato","excelente",
    "eficiente","buen servicio","correcto","soluci√≥n","acierto","confiable",
    "agradable","√©xito","contento","puntual","c√≥modo","limpio","tranquilo","frecuente",
    "bien se√±alizado","organizado","bien iluminado","accesible","ordenado","servicio amable",
    "buena frecuencia","r√°pida atenci√≥n","sin demora","sin problemas","fluido",
    "respetuoso","efectivo","bien comunicado","entendible","coherente","pr√°ctico",
    "agradable viaje","confortable","tranquilo viaje","eficiente horario","seguro transporte",
    "limpieza","bien cuidado","buena se√±alizaci√≥n","orden","excelente atenci√≥n"
]

# Alem√°n
neg_de = [
    "frustration","versp√§tung","wut","√§rger","√§rgernis","raub","√ºberfall","unsicher",
    "angst","teuer","unzufrieden","langsam","schlechter_service","problem","fehler",
    "mangel","entt√§uschung","ausfall","unbequem","schmutzig","laut","√ºberf√ºllt",
    "enge","unorganisiert","respektlos","gef√§hrlich","lange_wartezeit","schlechtes_wetter",
    "schlechte_beschilderung","verwirrung","fehlende_information","erm√ºdend","r√ºpelhaft",
    "unfreundlich","unzuverl√§ssig","chaotisch","stau","konfus","problematisch","verz√∂gerung",
    "√ºberlastet","ungem√ºtlich","veraltet","unpraktisch","fehlplan","schwierig","unangenehm"
]

pos_de = [
    "zufriedenheit","schnell","freude","vertrauen","sicher","g√ºnstig","exzellent",
    "effizient","guter_service","korrekt","l√∂sung","erfolg","verl√§sslich","angenehm",
    "gl√ºcklich","p√ºnktlich","komfortabel","sauber","ruhig","h√§ufig","gut_beschildert",
    "organisiert","gut_beleuchtet","barrierefrei","geordnet","freundlicher_service",
    "gute_frequenz","schnelle_bearbeitung","ohne_verz√∂gerung","problemfrei","flie√üend",
    "respektvoll","effektiv","gut_kommuniziert","verst√§ndlich","koh√§rent","praktisch",
    "angenehme_reise","komfortable_fahrt","ruhige_fahrt","effizienter_fahrplan","sicherer_transport",
    "sauberkeit","gut_gepflegt","gute_beschilderung","ordnung","ausgezeichneter_service"
]

# -------------------------------
# Funci√≥n SemAxis
# -------------------------------
def semaxis_score(embedding_tweet, embedding_neg, embedding_pos):
    axis = embedding_pos - embedding_neg
    score = np.dot(embedding_tweet - embedding_neg, axis) / np.dot(axis, axis)
    return score

# -------------------------------
# Ejecuci√≥n pipeline
# -------------------------------
if __name__ == "__main__":
    # 1Ô∏è‚É£ Cargar tweets
    if not os.path.exists(ARCHIVO_TWEETS):
        raise FileNotFoundError(f"No se encontr√≥ {ARCHIVO_TWEETS}")
    
    df = pd.read_csv(ARCHIVO_TWEETS)
    df = df[df["Tweet_limpio"].notna() & (df["Tweet_limpio"] != "")].reset_index(drop=True)
    print(f"‚úÖ {len(df)} tweets cargados.")

    # 2Ô∏è‚É£ Cargar embeddings existentes
    if not os.path.exists(ARCHIVO_EMBEDDINGS):
        raise FileNotFoundError(f"No se encontr√≥ {ARCHIVO_EMBEDDINGS}")
    
    embeddings_tweets = np.load(ARCHIVO_EMBEDDINGS)
    print(f"üíæ Embeddings cargados desde {ARCHIVO_EMBEDDINGS}")

    # 3Ô∏è‚É£ Reducir con UMAP (opcional)
    print("üîª Aplicando UMAP para reducci√≥n de dimensionalidad...")
    umap_model = UMAP(n_components=20, n_neighbors=30, min_dist=0.1, metric='cosine')
    embeddings_umap = umap_model.fit_transform(embeddings_tweets)
    print(f"üìâ Reducci√≥n completada a {embeddings_umap.shape[1]} dimensiones.")

    # 4Ô∏è‚É£ Calcular SemAxis
    print("‚ö° Calculando SemAxis scores...")
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    modelo = SentenceTransformer(DEFAULT_MODELO, device=device)
    
    # Embeddings de semillas (bigramas se codifican completos)
    embedding_neg_es = modelo.encode(neg_es, convert_to_numpy=True).mean(axis=0)
    embedding_pos_es = modelo.encode(pos_es, convert_to_numpy=True).mean(axis=0)
    embedding_neg_de = modelo.encode(neg_de, convert_to_numpy=True).mean(axis=0)
    embedding_pos_de = modelo.encode(pos_de, convert_to_numpy=True).mean(axis=0)

    semaxis_scores = []

    for i, row in df.iterrows():
        emb = embeddings_tweets[i]
        lang = row["Lang"]

        if lang == "E":
            score = semaxis_score(emb, embedding_neg_es, embedding_pos_es)
        else:
            score = semaxis_score(emb, embedding_neg_de, embedding_pos_de)
        semaxis_scores.append(score)

    df["SemAxis_Score"] = semaxis_scores

    # 5Ô∏è‚É£ Clustering 2 clusters sobre SemAxis
    kmeans = KMeans(n_clusters=2, random_state=42)
    df["Cluster_SemAxis"] = kmeans.fit_predict(df[["SemAxis_Score"]])
    print("‚úÖ Clusters SemAxis generados.")

    # 6Ô∏è‚É£ Guardar CSV final
    df.to_csv(ARCHIVO_FINAL, index=False, encoding='utf-8-sig')
    print(f"‚úÖ Pipeline completo finalizado. CSV guardado en {ARCHIVO_FINAL}")
